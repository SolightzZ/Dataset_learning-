# Lab 4 ‚Äì KNN Classification

## üìå ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏° (Overview)

‡πÅ‡∏•‡∏õ‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ú‡∏π‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏° (Down / TD) ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ **K-Nearest Neighbors (KNN)**

- ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏à‡∏≤‡∏Å‡πÅ‡∏ö‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö: Peabody, Raven, SAQ
- ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
- ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì **Euclidean Distance** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ù‡∏∂‡∏Å
- ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏à‡∏≤‡∏Å K ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ö‡πâ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î

---

## ‚öôÔ∏è ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (Requirements)

````bash
pip install numpy pandas
## üß© ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î (Code Structure)

1. **‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Load & Prepare Dataset)**
   - ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå CSV ‡∏î‡πâ‡∏ß‡∏¢ `pandas.read_csv`
   - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å features (`Peabody`, `Raven`, `SAQ`)
   - ‡πÅ‡∏õ‡∏•‡∏á label `Group` ‚Üí Down = 0, TD = 1
   - ‡∏£‡∏ß‡∏° features ‡πÅ‡∏•‡∏∞ label ‡πÄ‡∏õ‡πá‡∏ô numpy array

2. **‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö (User Input for Test Data)**
   - ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ x1, x2, x3 ‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ

3. **‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Euclidean Distance**
   - ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á test data ‡∏Å‡∏±‡∏ö train data ‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ï‡∏±‡∏ß

4. **‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á (Sort Distances)**
   - ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ index ‡∏Ç‡∏≠‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ö‡πâ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î

5. **‡πÄ‡∏•‡∏∑‡∏≠‡∏Å K ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ö‡πâ‡∏≤‡∏ô (Select K Nearest Neighbors)**
   - K = 3 (‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ)
   - ‡∏î‡∏∂‡∏á‡∏Ñ‡∏•‡∏≤‡∏™‡∏Ç‡∏≠‡∏á K ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ö‡πâ‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î

6. **‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ (Count Classes & Predict)**
   - ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏Ñ‡∏•‡∏≤‡∏™‡πÉ‡∏ô K ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ö‡πâ‡∏≤‡∏ô
   - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏•‡∏≤‡∏™‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå

7. **‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Display Result)**
   - ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• test data ‡πÅ‡∏•‡∏∞‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
## üìÇ ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î (Code Example)

```python
import numpy as np
import pandas as pd

# ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
file_path = r"Dataset path learning floor matrix task.csv"
data = pd.read_csv(file_path)
X = data[['Peabody', 'Raven', 'SAQ']].values
y = data['Group'].map({'Down': 0, 'TD': 1}).values
train_data = np.column_stack((X, y))

# ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ
x1_test = float(input("‡∏Å‡∏£‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤ x1 (Peabody): "))
x2_test = float(input("‡∏Å‡∏£‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤ x2 (Raven): "))
x3_test = float(input("‡∏Å‡∏£‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤ x3 (SAQ): "))
test_data = np.array([x1_test, x2_test, x3_test])

# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Euclidean Distance
distances = np.sqrt(np.sum((train_data[:, :3] - test_data) ** 2, axis=1))
indices = np.argsort(distances)

# ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å K ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ö‡πâ‡∏≤‡∏ô
K = 3
nearest_classes = train_data[indices[:K], 3]

# ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏•‡∏≤‡∏™‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢
class_counts = np.bincount(nearest_classes.astype(int))
predicted_class = np.argmax(class_counts)

# ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
print("\nTest Data:", test_data)
if predicted_class == 0:
    print("‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: Down Syndrome")
else:
    print("‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢: TD (‡∏õ‡∏Å‡∏ï‡∏¥)")

---

### üìù ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏ (Notes)

```markdown
## üìù ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏ (Notes)

- K ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
- ‡∏Ñ‡πà‡∏≤ Euclidean Distance ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
- ‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏°‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà `"Dataset path learning floor matrix task.csv"` ‡∏î‡πâ‡∏ß‡∏¢ path ‡∏à‡∏£‡∏¥‡∏á‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì
- ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÉ‡∏ä‡πâ majority vote ‡∏Ç‡∏≠‡∏á K ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏ö‡πâ‡∏≤‡∏ô‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î



# Lab 5 ‚Äì ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á

## üìÇ ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Dataset)

‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤: `Dataset path learning floor matrix task.csv`

**Features (‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞):**

- Peabody
- Raven
- SAQ

**Target (‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢):**

- Group ‚Üí ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô Down = 0, TD = 1

**‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ (Missing Values):**

- ‡πÉ‡∏ä‡πâ mean imputation

## üß© ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î (Code Structure)

1. **‡πÇ‡∏´‡∏•‡∏î‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Load Dataset)**

   - ‡πÉ‡∏ä‡πâ `pandas.read_csv` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
   - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡∏î‡πâ‡∏ß‡∏¢ `SimpleImputer`

2. **‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Cross Validation**

   - ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ K-Fold Cross Validation (n=5)
   - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•:
     - Naive Bayes
     - Decision Tree
     - KNN

3. **‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô (Evaluation Metrics)**

   - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ fold ‡∏à‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì:
     - Confusion Matrix
     - Accuracy
     - Recall
     - Precision
     - F1-Measure
   - ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏•‡∏≠‡∏á

4. **‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• (Summary of All Models)**
   - ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•
   - ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢

## üìä ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (Example Output)

```yaml
================ Fold 1 (NaiveBayes) ================
Confusion Matrix:
               Pred Down   Pred TD
Actual Down         5          2
Actual TD           1          7

Accuracy : 85.71%
Recall   : 87.50%
Precision: 77.78%
F-Measure: 82.35%
...

=========== Summary NaiveBayes (Average from 5 folds) ===========
Mean Accuracy : 82.50%
Mean Recall   : 83.00%
Mean Precision: 80.50%
Mean F-Measure: 81.70%

## üìù ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏ (Notes)

- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ k ‡πÉ‡∏ô KNN ‡πÑ‡∏î‡πâ ‡πÇ‡∏î‡∏¢‡∏Ñ‡πà‡∏≤‡∏î‡∏µ‡∏ü‡∏≠‡∏•‡∏ï‡πå‡∏Ñ‡∏∑‡∏≠ k=3
- ‡∏Ñ‡πà‡∏≤ random seed ‡∏ñ‡∏π‡∏Å‡∏ï‡∏±‡πâ‡∏á‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà 42 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏≥‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ (reproducibility)
- ‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏°‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà `"Dataset path learning floor matrix task.csv"` ‡∏î‡πâ‡∏ß‡∏¢ path ‡∏à‡∏£‡∏¥‡∏á‡∏Ç‡∏≠‡∏á‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì
````
